# DAMP-light: прототип ключевых этапов

## Назначение репозитория
Проект демонстрирует упрощённую версию pipeline «от стимула к смыслу» из статьи про DAMP. Скрипт `main.py`:

1. Загружает изображения цифр (по умолчанию — `MNIST`, 28×28, яркости в [0, 1]).
2. Строит первичный разрежённый код через «скважины» Собеля (`PrimaryEncoderKeyholeSobel`).
3. Укладывает коды на двумерную решётку локальными свапами (`Layout2DNew`).
4. Собирает детекторы (круги/эллипсы) над активными областями раскладки и превращает их в бинарный эмбеддинг (`DetectorSpace`).
5. Обучает kNN-классификатор по метрике Жаккара (`KNNJaccard`) и печатает отчёты.
6. Сохраняет визуальные артефакты: PDF с разбором отдельных примеров и сводные карты активаций.

## Зависимости
Проект не требует специальных фреймворков, достаточно стандартного стека научного Python. Установите:

Сделайте виртуальное окружение `python -m venv venv` и активируйте его через `venv\Scripts\activate.ps1` (Windows) или `venv\activate` (Linux).
Установите зависимости: `pip install -r requirements.txt`.
```bash
pip install -r requirements.txt
```

`rerun` используется для стриминговых визуализаций раскладки и детекторов. Если он не нужен, можно заменить импорт в `training_cache.py` на заглушку, но по умолчанию библиотека обязательна: без неё `load_or_train` не запустится.

## Быстрый старт
1. Склонируйте репозиторий и перейдите в папку проекта.
2. Установите зависимости (см. выше).
3. Запустите основной сценарий:
   ```bash
   python main.py
   ```
   Первый запуск обучает весь конвейер и создаёт кэш `{dset}_training_cache.pkl` (по умолчанию `mnist_training_cache.pkl`).
4. Повторные запуски читают кэш и пересчитывают только тестовые эмбеддинги и отчёты. Удалите файл кэша, чтобы переобучить всё с нуля.

После завершения в консоли появится полный отчёт с accuracy, precision/recall/F1 по классам и средним числом активных битов в первичном коде и эмбеддинге. Финальный kNN обучается с `k=3` (внутри `KNNJaccard`).

## Архитектура pipeline
### 1. Первичный кодировщик: `PrimaryEncoderKeyholeSobel`
* Размер «вселенной» битов `B=1024`.
* На каждом изображении выбирается решётка из 25 скважин (5×5) размером 9×9.
* Для каждой скважины считаются градиенты Собеля, строится взвешенная гистограмма направлений (6 бинов), и доминирующий угол активирует `bits_per_keyhole=12` битов.
* Слабые окна (средняя нормированная величина < 0.30) отбрасываются. Если всё отфильтровано, берётся самое «сильное» окно как fallback.
* Допускается переиспользование битов между скважинами (`unique_bits=False`), что повышает плотность, но экономит бюджет B.
* Итог первичного кодирования — множество индексов (set[int]), обычно от сотни до нескольких сотен элементов.

Для отладки доступны вспомогательные методы: например, `code_dominant_orientation` оценивает доминирующий угол по активным битам.

### 2. Раскладка: `Layout2DNew`
* Коды укладываются на почти квадратную сетку (по количеству обучающих примеров). В проекте используется `R_far=12` и `R_near=3` с 200 эпохами на каждую фазу.
* Фаза FAR минимизирует локальную энергию `sim × dist`, переставляя пары точек, если после свапа сумма уменьшается.
* Фаза NEAR усиливает локальную дисперсию: свап принимается, если энергия после перестановки становится больше — тем самым класс похожих кодов «разжимается» вблизи.
* В процессе обучения включён хук `on_epoch` (в `training_cache.load_or_train`), который логирует состояние в `rerun` для интерактивного просмотра.

### 3. Детекторное пространство: `DetectorSpace`
* Для каждой тренировочной точки вычисляется адаптивная карта активаций: косинус Жаккара (через `cosbin`) порогуется по перцентилю 0.88 с нижней границей `lam_floor=0.06`. Если активных клеток меньше 35, дополнительно берутся топ-значения.
* Из связных компонент на карте строятся кандидаты детекторов. Круги используются для компактных кластеров, эллипсы (с PCA-подходом и коэффициентом растяжения ≥ 1.4) — для вытянутых областей. Радиусы масштабируются коэффициентом 1.6.
* Кандидаты сортируются по размеру компоненты; дальше фильтруются по минимальному расстоянию между центрами (`min_center_dist=1.6`) и ограничиваются `max_detectors=260`.
* Каждому детектору выделяется уникальный бит в эмбеддинге (`emb_bits=256`). Срабатывание происходит, если доля активных клеток внутри фигуры ≥ `mu=0.15`.
* Функция `det.embed(code)` возвращает множество битов эмбеддинга. Именно оно подаётся в kNN и визуализации.

### 4. Классификация: `KNNJaccard`
* Простая реализация kNN с метрикой Жаккара и весами, обратно пропорциональными расстоянию.
* В `main.py` используется `k=3`; при равенстве голосов побеждает класс с лучшей суммарной величиной весов.

## Кэширование и повторное использование
Модуль `training_cache.py` инкапсулирует шаги обучения. Он проверяет наличие файла `{dset}_training_cache.pkl` и при необходимости создаёт новый набор `(enc, lay, det, Z_train, Z_test)`. Это ускоряет эксперименты: повторное выполнение `main.py` не запускает раскладку и поиск детекторов заново.

## Визуализация и артефакты
Основной сценарий создаёт несколько файлов:

* `mnist_embedding_core_class-<digit>.png` — тепловая карта «ядра» эмбеддингов выбранного класса.
* `mnist_pipeline_<digit>x<count>.pdf` — серия страниц с результатом `visualize_pipeline` для случайных примеров заданной цифры.
* `mnist_overlay_class<digit>_<count>_activation.pdf` — накопительная карта активаций детекторов для класса.

Функции из `viz.py` позволяют отдельно вызывать `visualize_pipeline`, получать карты накрытия детекторами и т.д. Для интерактивного анализа раскладки/детекторов предусмотрен стриминг в Rerun (`layout_rerun.py`, `training_cache.py`).

## Адаптация под другой датасет
В `main.py` есть заготовка для `sklearn.datasets.load_digits` (8×8). Чтобы переключиться:

1. Замените значение переменной `dset` на другое название и раскомментируйте блок `else` (или оберните выбор датасета аргументами функции `main`).
2. Обновите параметры `PrimaryEncoderKeyholeSobel` и `Layout2DNew`, если размер изображений отличается.
3. Удалите старый кэш (`rm <название>_training_cache.pkl`), чтобы пересобрать pipeline с новыми настройками.

